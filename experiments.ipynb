{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install torch\n",
    "# %pip install emoji==0.6.0\n",
    "# %pip install TweetNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Repositories\\GreenSecurity-FirstExperiment\\.conda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import WordNetLemmatizer\n",
    "import gensim\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import json\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "nltk.download('punkt')\n",
    "from TweetNormalizer import normalizeTweet\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Administrator\\Downloads\\parler-hate-speech-main\\parler-hate-speech-main\\parler_annotated_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4772              [O, O, O, O, O, O, O, O, O, O, O, O, O]\n",
       "2299    [O, O, O, I-MISC, O, O, O, O, O, O, O, O, O, O...\n",
       "9219    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "4511                                   [O, O, O, O, O, O]\n",
       "1849                                  [B-PER, O, O, O, O]\n",
       "                              ...                        \n",
       "7450    [O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O,...\n",
       "7568    [B-PER, I-PER, O, O, O, O, O, O, O, B-MISC, I-...\n",
       "2424    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "8134    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "314     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = Model(TokensClassTasks.NER)\n",
    "#split too long posts\n",
    "df.text = df.text.apply(lambda x: [x for x in split_rows(x)])\n",
    "df = df.explode(\"text\")\n",
    "#inference\n",
    "df.sample(100).text.apply(ner_model.run_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9596430677f980318f03c286a56e08afff504ebd1ea48afc7d8c2a417d941c92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
