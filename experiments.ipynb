{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install torch\n",
    "# %pip install emoji==0.6.0\n",
    "# %pip install TweetNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to https://132.72.66.176:9981/api/sessions?1673937161449 failed, reason: self signed certificate. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import WordNetLemmatizer\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import json\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "nltk.download('punkt')\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Administrator\\Downloads\\parler-hate-speech-main\\parler-hate-speech-main\\parler_annotated_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split too long posts\n",
    "df.text = df.text.apply(lambda x: [x for x in split_rows(x)])\n",
    "df = df.explode(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = Model(TokensClassTasks.NER)\n",
    "#inference\n",
    "df['ner'] = df.text.apply(ner_model.run_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_model = Model(TokensClassTasks.POS_TAGGING)\n",
    "#inference\n",
    "df['pos_tag'] = df.text.apply(pos_tag_model.run_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ner_pos_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:57:06) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83442504b71d914325260cede427dd3998e41b9544a3b4fab4b8796da0ce6d33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
